{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 8 exercises\n",
    "\n",
    "These are sample answers for the in-class exercises in Session 8 of PHAS0030.  You should make sure that you can do these yourself! The further work exercises will be in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We always start with appropriate imports; note the use of the IPython magic\n",
    "# command to set up Matplotlib within the notebook\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pseudo-random numbers\n",
    "\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Natoms = 1000\n",
    "tmax = 1000       # seconds\n",
    "dt = 1.0          # seconds\n",
    "tau_Tl = 3.053*60 # half-life in seconds\n",
    "t0_Tl  = tau_Tl/np.log(2.0)\n",
    "\n",
    "# Store populations at each timestep\n",
    "pop_Tl = np.zeros(tmax+1,dtype=int)\n",
    "pop_Pb = np.zeros(tmax+1,dtype=int)\n",
    "# Initial condition\n",
    "pop_Tl[0] = Natoms\n",
    "# Decay probability per timestep\n",
    "prob_decay = 1.0 - np.exp(-dt/t0_Tl)\n",
    "\n",
    "for i in range(tmax):\n",
    "    t = int(i*dt)\n",
    "    # Array with chance for each Tl to decay\n",
    "    prob_samp = rng.random(pop_Tl[t])\n",
    "    # Sum to find number that decay\n",
    "    decay_total = np.sum(np.where(prob_samp<prob_decay,1,0))\n",
    "    # Update populations\n",
    "    pop_Tl[t+1] = pop_Tl[t] - decay_total\n",
    "    pop_Pb[t+1] = pop_Pb[t] + decay_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarr = np.arange(0,tmax+dt,dt)\n",
    "plt.plot(tarr,pop_Tl,label='Tl')\n",
    "plt.plot(tarr,pop_Pb,label='Pb')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time in s\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.title(\"Decay of sample of Tl atoms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the expected exponential decay in Tl atoms, with the appropriate increase in Pb atoms.\n",
    "\n",
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 151\n",
    "mid = 75\n",
    "# Trajectory storage\n",
    "traj = np.zeros((side,side))\n",
    "this_x = mid\n",
    "this_y = mid\n",
    "traj[this_x,this_y] = 1\n",
    "Nsteps = 10000\n",
    "# Neighbours\n",
    "neigh = np.array([[-1,0],[1,0],[0,-1],[0,1]])\n",
    "\n",
    "# Storage for the path\n",
    "line = np.zeros((Nsteps+1,2))\n",
    "line[0] = np.array([this_x,this_y])\n",
    "for i in range(Nsteps):\n",
    "    # Pick neighbour\n",
    "    neigh0 = rng.integers(4)\n",
    "    this_x += neigh[neigh0,0]\n",
    "    this_y += neigh[neigh0,1]\n",
    "    # Hard-wall boundaries\n",
    "    if(this_x>side-1):\n",
    "        this_x -= 2\n",
    "    if(this_y>side-1):\n",
    "        this_y -= 2\n",
    "    if(this_x<0):\n",
    "        this_x += 2\n",
    "    if(this_y<0):\n",
    "        this_y += 2\n",
    "    # Update trajectory and path\n",
    "    traj[this_x,this_y] += 1\n",
    "    line[i+1] = np.array([this_x,this_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing number of times each point was visited\n",
    "plt.imshow(traj,origin='lower')\n",
    "plt.colorbar(label='Number of visits')\n",
    "plt.title(\"Map of random walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution for Nsteps\n",
    "x = np.linspace(-mid,mid,side)\n",
    "y = np.linspace(-mid,mid,side)\n",
    "x2d, y2d = np.meshgrid(x,y)\n",
    "prob_r = 2 * np.sqrt(x2d*x2d + y2d*y2d) * np.exp(-(x2d*x2d+y2d*y2d)/Nsteps) / Nsteps\n",
    "plt.imshow(prob_r,origin='lower')\n",
    "plt.colorbar(label='Probability')\n",
    "# Plot path taken by particle\n",
    "plt.plot(line[:,0],line[:,1])\n",
    "plt.title('Path and probability distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the location of the particle fits quite well with the probability distribution, but also that the array we have used is maybe too small for the problem.\n",
    "\n",
    "## 4. Probability distributions\n",
    "\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dist(Nsamp,mu,sigma):\n",
    "    \"\"\"Average Nsamp samples from uniform distribution\n",
    "    \n",
    "    Inputs:\n",
    "    Nsamp  Number of samples\n",
    "    mu     Mean of distribution\n",
    "    sigma  Width of distribution\n",
    "    \n",
    "    Output:\n",
    "    Mean of Nsamp samples\n",
    "    \"\"\"\n",
    "    width = np.sqrt(3*Nsamp)*sigma\n",
    "    samp = rng.uniform(mu-width, mu+width,Nsamp)\n",
    "    return(np.sum(samp)/Nsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndist = 100000\n",
    "Nsamp = 10\n",
    "mu = 0.0\n",
    "sigma = 1.0\n",
    "table = np.zeros(Ndist)\n",
    "for i in range(Ndist):\n",
    "    table[i] = sample_dist(Nsamp,mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output mean & standard deviation\n",
    "print(f\"Mean: {np.mean(table)}\")\n",
    "print(f\"SD:   {np.std(table)}\")\n",
    "\n",
    "# Plot histogram\n",
    "a = plt.hist(table,bins=50,density=True,label=f'{Nsamp} samples')\n",
    "\n",
    "# Plot expected distribution\n",
    "x = np.linspace(-3,3)\n",
    "sdist = 1.0\n",
    "plt.plot(x,np.exp(-x*x/(2*sdist*sdist))/np.sqrt(2*np.pi*sdist*sdist),label='Expected distribution')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.title(\"Testing central limit theorem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that Ndist=10,000 was adequate but 100,000 gives a better result.  Once Nsamp>10 we get a good normal distribution.\n",
    "\n",
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_method_uniform(n_samples,a,b,h):\n",
    "    \"\"\"Rejection method drawing from uniform x from a to b, maximum h\n",
    "    \n",
    "    Inputs:\n",
    "    n_samples  Number of samples\n",
    "    a, b       Limits of uniform distribution\n",
    "    h          Height of uniform distribution\n",
    "    \n",
    "    Output:\n",
    "    result     Array of n_samples numbers\n",
    "    \"\"\"\n",
    "    result = np.zeros(n_samples)\n",
    "    n_accept = 0\n",
    "    n_counts = 0\n",
    "    for i in range(n_samples):\n",
    "        reject = True\n",
    "        while reject:\n",
    "            n_counts += 1\n",
    "            x = rng.uniform(a,b)\n",
    "            z = h # p(x) is uniform\n",
    "            qx = (1+x*x)*np.exp(-0.5*x*x)/(2*np.sqrt(2*np.pi))\n",
    "            nx = z*rng.random()\n",
    "            if(nx<qx):\n",
    "                reject = False\n",
    "                result[n_accept] = x\n",
    "                n_accept += 1\n",
    "    print(\"Ran \",n_counts,\" tests for \",n_samples,\" samples\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamp = 100000\n",
    "samp_uni   = rejection_method_uniform(Nsamp,-5,5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of rejection method\n",
    "a = plt.hist(samp_uni,bins=50,density=True,label='Rejection method')\n",
    "\n",
    "# Set up target distribution\n",
    "xplot = np.linspace(-5,5)\n",
    "xplot2 = xplot*xplot\n",
    "targ = (1+xplot2)*np.exp(-0.5*xplot2)/(2*np.sqrt(2*np.pi))\n",
    "plt.plot(xplot,targ,label='Expected distribution')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.title(\"Testing rejection method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the histogram fits the target distribution well, though the method is quite inefficient with roughly 80% of numbers discarded.\n",
    "\n",
    "## 5. Monte Carlo methods\n",
    "\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_int(x):\n",
    "    \"\"\"Function to be integrated: x^{-1/3} + x/10\"\"\"\n",
    "    return x**(-1/3) + 0.1*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Nsamp in [1e3, 1e4, 1e5, 1e6]:\n",
    "    total = 0.0\n",
    "    total = np.sum(func_int(rng.random(int(Nsamp))))\n",
    "    print(\"Integral is \",total/Nsamp,\" with \",Nsamp,\" samples\")\n",
    "    print(\"Error is \",total/Nsamp - 1.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the result is reliable when we reach 100,000 samples, but not really before that (just over 1% error is unlikely to be acceptable).\n",
    "\n",
    "Note also that if we were to use a `for` loop to calculate the sum (`total` in this case) the calculation is *much* slower.\n",
    "\n",
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Nsamp in [1e3, 1e4, 1e5, 1e6]:\n",
    "    thisy = rng.random(int(Nsamp))\n",
    "    thisx = thisy**1.5\n",
    "    total = np.sum(func_int(thisx)/(2.0/(3.0*thisx**(1/3))))\n",
    "    print(\"Integral is \",total/Nsamp,\" with \",Nsamp,\" samples\")\n",
    "    print(\"Error is \",total/Nsamp - 1.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the error found with importance sampling converges much faster than with uniform sampling.  The result with 1,000 samples is reliable.\n",
    "\n",
    "## 6. Monte Carlo simulations\n",
    "\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxlen = 50\n",
    "B_over_kT = 0.0\n",
    "J_over_kT = 0.5\n",
    "spins = (-1)**rng.integers(0,2,size=(boxlen,boxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(spins)\n",
    "plt.title('Initial spins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sum over neighbours\n",
    "sum_neigh_spins = (np.roll(spins,1,axis=0)+np.roll(spins,-1,axis=0)+\n",
    "                   np.roll(spins,1,axis=1)+np.roll(spins,-1,axis=1))\n",
    "etot = -np.sum(spins*(B_over_kT + J_over_kT*sum_neigh_spins))\n",
    "print(\"Starting energy is \",etot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the starting conformation is random, this initial energy has little significance\n",
    "\n",
    "### Question 3\n",
    "\n",
    "The easiest way to write the update is just to calculate the energy twice, as shown in this routine `update`.  However, we can just calculate the energy change locally (just for the flipped spin) as shown in the routine `update_local` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(i,j):\n",
    "    \"\"\"Update move for MC Ising model\n",
    "    \n",
    "    Assumes that the 2D array spins is defined externally\n",
    "    and changes this if the Metropolis criterion is met.\n",
    "    \n",
    "    Inputs:\n",
    "    i, j  Location of spin to flip\n",
    "    \n",
    "    Output:\n",
    "    de    Change of energy\n",
    "    \"\"\"\n",
    "    sum_neigh_spins = (np.roll(spins,1,axis=0)+np.roll(spins,-1,axis=0)+\n",
    "                   np.roll(spins,1,axis=1)+np.roll(spins,-1,axis=1))\n",
    "    e_init = -np.sum(spins*(B_over_kT + J_over_kT*sum_neigh_spins))\n",
    "    # Now flip the spin\n",
    "    spins[i,j] *= -1\n",
    "    # Find new energy\n",
    "    sum_neigh_spins = (np.roll(spins,1,axis=0)+np.roll(spins,-1,axis=0)+\n",
    "                   np.roll(spins,1,axis=1)+np.roll(spins,-1,axis=1))\n",
    "    e_new = -np.sum(spins*(B_over_kT + J_over_kT*sum_neigh_spins))\n",
    "    de = e_new - e_init\n",
    "    p = np.exp(-de)\n",
    "    # restore spin if move not accepted\n",
    "    if de>0 and rng.random() > p:\n",
    "        spins[i,j] = -spins[i,j]\n",
    "        de = 0.0\n",
    "    return de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_local(i,j):\n",
    "    \"\"\"Update move for MC Ising model\n",
    "    \n",
    "    Assumes that the 2D array spins is defined externally\n",
    "    and changes this if the Metropolis criterion is met.\n",
    "    \n",
    "    Inputs:\n",
    "    i, j  Location of spin to flip\n",
    "    \n",
    "    Output:\n",
    "    de    Change of energy\n",
    "    \"\"\"\n",
    "    im = (i-1)%boxlen\n",
    "    ip = (i+1)%boxlen\n",
    "    jm = (j-1)%boxlen\n",
    "    jp = (j+1)%boxlen\n",
    "    sum_neigh_spins = spins[im,j] + spins[ip,j] + spins[i,jm] + spins[i,jp]\n",
    "    # The change in energy accounts for flip from -1 to +1 or vice versa\n",
    "    de_local = 2*spins[i,j]*(J_over_kT*sum_neigh_spins + B_over_kT)\n",
    "    p = np.exp(-de_local)\n",
    "    # flip the spin if move accepted\n",
    "    if de_local<0 or rng.random() < p:\n",
    "        spins[i,j] = -spins[i,j]\n",
    "    else:\n",
    "        de_local = 0.0\n",
    "    return de_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "This took 10-15 seconds to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise storage\n",
    "Nsteps = 50000\n",
    "long_range_order = np.zeros(Nsteps+1)\n",
    "etot = np.zeros(Nsteps+1)\n",
    "long_range_order[0] = np.sum(spins)/np.size(spins)\n",
    "\n",
    "# Initial energy\n",
    "sum_neigh_spins = (np.roll(spins,1,axis=0)+np.roll(spins,-1,axis=0)+\n",
    "                   np.roll(spins,1,axis=1)+np.roll(spins,-1,axis=1))\n",
    "etot[0] = -np.sum(spins*(B_over_kT + J_over_kT*sum_neigh_spins))\n",
    "\n",
    "# Figure for plots\n",
    "figIsing = plt.figure(figsize=(12,6))\n",
    "index = 1\n",
    "spin_total = 0\n",
    "spin2_total = 0\n",
    "for i in range(Nsteps):\n",
    "    # Choose spin at random\n",
    "    this_i = rng.integers(boxlen)\n",
    "    this_j = rng.integers(boxlen)\n",
    "    # Test for update: choose version\n",
    "    #de = update(this_i,this_j)\n",
    "    de = update_local(this_i,this_j)\n",
    "    # Accumulate and store characteristic data\n",
    "    sum_neigh_spins = (np.roll(spins,1,axis=0)+np.roll(spins,-1,axis=0)+\n",
    "                       np.roll(spins,1,axis=1)+np.roll(spins,-1,axis=1))\n",
    "    etot[i+1] = -np.sum(spins*(B_over_kT + J_over_kT*sum_neigh_spins))\n",
    "    long_range_order[i+1] = np.sum(spins)/np.size(spins)\n",
    "    spin_total += np.sum(spins)/np.size(spins)\n",
    "    spin2_total += np.sum(spins)*np.sum(spins)/(np.size(spins)*np.size(spins))\n",
    "    # Plot\n",
    "    if i%5000==0:\n",
    "        ax = figIsing.add_subplot(3,4,index)\n",
    "        image = ax.imshow(spins,interpolation='none')\n",
    "        plt.colorbar(mappable=image)\n",
    "        index +=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you either need to make the figure large, or use the argument `interpolation='none'` to `imshow`, otherwise it will appear to have values between -1 and 1 (i.e. not just 1 and -1) which is quite wrong.\n",
    "\n",
    "Physically we see that the spins tend to align with the external magnetic field, though we don't see complete alignment (that would take a very long time unless we made the field much larger).\n",
    "\n",
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(long_range_order)\n",
    "plt.xlabel('MC step')\n",
    "plt.ylabel('Mean spin')\n",
    "plt.title('Long-range order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(etot)\n",
    "plt.xlabel('MC step')\n",
    "plt.ylabel('E/kT')\n",
    "plt.title('Total energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_spin = spin_total/(Nsteps)\n",
    "print(\"Ave spin squared: \",spin2_total/Nsteps)\n",
    "sd_spin = np.sqrt(spin2_total/Nsteps - ave_spin*ave_spin)\n",
    "print(\"Average spin: \",ave_spin,\" with SD \",sd_spin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an initial period when the system equilibrates, we see that the energy and average spin fluctuate around a constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
